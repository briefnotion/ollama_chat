0.028-241219
  - Created a way to recall previous conversation. It works well enough for now.

0.027-241217
  - Created Role place holders for the chat history.
  - Chat history is being saved with date and time. 
      No derectory existance checks are being made, so directories will need to 
      be made:
        string directory_name_unprocessed = "history_unprocessed/";
        string directory_name_processed =   "history_processed/";
      Working directory is to set at (main.cpp): 
        sdSystem.MEMORY.PROPS.WORKING_DIRECTORY = "~/chat_api/";

0.026-241216
  - Continued work on generating a maintenace mode which is working now by asking to 
      "go into maintenance mode." Established a, fairly stable, model to handle 
      future procedures and routines related to making system calls to the ai system.

0.025-241211
  - Continued work on generating a maintenace mode.

0.024-241210
  - Continued work on generating a maintenace mode.

0.023-241209
  - Put some work on generating a maintenace mode.

0.022-241205
  - Moved some things around, reorganized some things, and rewrote some other things,
      because things were not going to work the way they were.
  
      Lost some functionallity with database manangement, but that was going to be rewitten
      anyway.

0.021-241204
  - Compartmentalized a few things to begin preparing for other functions.

0.020-241203
  - Made some progress with providing information from relevant documents when answering
      questions.  Previouse attempt in .019 didn't work.

0.019-241202
  - Made some progress with the RAG support.

0.018-241201
  - Started looking for solutions to combine embedded text results with the llm results.
  - Commands changed again to avoid conflicts with normal text.  They are:
      " embeding"
      " import"
      " erase"
      " list"
      " i"
      " o"

      I plan to do away with all these eventually.

0.017-241130
  - Added option n to the embedding access routines to attempt to pull and combine a response from
      both the Ollama LLM and the VectorDB.
      Example:
        nTell Me about rubber ducks.

0.016-241128
  - Did some more work with embedding.  Current test routines are as follows:
    Simple embedding tools were added, accessed by the first character of the input line:
      Example:
        eTell Me about rubber ducks.              Call python script to handle question and answer question.
        m~/testdocs/rubberduckdetails.txt         Import document into the database
        b                                         Completely erase all data in embedding database.
        d                                         List topics in database.
        iTell Me about rubber ducks.              Call python script to gather documents with question,
                                                  then forwards thos docs to chat_ollama to answer while
                                                  preserving context.  Also, faster because model doesn'test
                                                  need to be loaded in python system.

      Provided that you have an enviornment properly set up and configured via VECTORDB_SYSTEM.PROPS,
        results should be displayed.  My defaults are in "vectordb_python_api.h" in the
        "VECTORDB_PYTHON_API_PROPERTIES" class.

0.015-241125
  - Rearranged some components.
  - Added a few of the scipts that I call to start things.
  - Added a few more python scipts.

0.014-241123
  - Changed fled_time to work with double instead of unsigned long.  Increases accuray.
  - The program time clock has been changed from system_clock to steady_clock.  Increases stability.

  - A few simple embedding tools were added, accessed by the first character of the input line:
      Example:
        m~/testdocs/rubberduckdetails.txt         Import document into the database
        eWrite a quick story about rubber ducks.  Request info about the documents in the database.

      Provided that you have an enviornment properly set up and configured via VECTORDB_SYSTEM.PROPS,
        results should be displayed.  My defaults are in "vectordb_python_api.h" in the
        "VECTORDB_PYTHON_API_PROPERTIES" class.

0.013-241122
  - A simple RAG call is wrapped in a thread.
  - Made a few changes to the CMakeList.txt file.
  
0.012-241121
  - Started wrapping embedding into a thread.

0.011-241115
  - Successful OllamaDB fetch made via Python scipts.
  - Clean up some tty_io routines.

0.010-241114
  - Slow progress. Embedding with RAG support still doesn't work.  I'm updating git
      with the latest progress.

0.009-241105
  - Slow progress. Embedding with RAG support still doesn't work.  I'm updating git
      with the latest progress.

0.008-241028
  - THIS BUILD DOES NOT WORK:
      On line 8 of ollama_api.h, if (#include "ollama.hpp") is not commented out,
        line 54 of chromadb_api.cpp (chromadb::Client client("http", "localhost", "8000");)
        will throw the exceotion:
          Include this for: Fatal glibc error: pthread_mutex_lock.c:94 (___pthread_mutex_lock): assertion failed: mutex->__data.__owner == 0

0.007-241025
  - Restoration after system migration
  
0.006-241015
- Created a simple TTY_Interface.
    Its not finished, and i didnt put any limit on the size of the text
    box.  Works ok.  Probably spent more time on it than I should've.
- Changed other parts of the code.

0.005_241014
  - Code is running better.
  - Context is working
  
0.004_241013
  - built ollama_api
  - built ollama_helper
  - built threading

0.003_241012
  - Async communication to Ollama is working but still needs
      attention.
  - Corrected an errer if fled_time.

0.002_241011
  - Started building main structure.
  - Testing routines to see what works.

0.001_241010
  - First write, compile, and publish to github.