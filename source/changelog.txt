0.021-241204
  - Compartmentalized a few things to begin preparing for other functions. 

0.020-241203
  - Made some progress with providing information from relevant documents when answering 
      questions.  Previouse attempt in .019 didn't work.

0.019-241202
  - Made some progress with the RAG support.

0.018-241201
  - Started looking for solutions to combine embedded text results with the llm results.
  - Commands changed again to avoid conflicts with normal text.  They are:
      " embeding"
      " import"
      " erase"
      " list"
      " i"
      " o"

      I plan to do away with all these eventually.

0.017-241130
  - Added option n to the embedding access routines to attempt to pull and combine a response from 
      both the Ollama LLM and the VectorDB.
      Example:
        nTell Me about rubber ducks. 

0.016-241128
  - Did some more work with embedding.  Current test routines are as follows:
    Simple embedding tools were added, accessed by the first character of the input line:
      Example:
        eTell Me about rubber ducks.              Call python script to handle question and answer question.
        m~/testdocs/rubberduckdetails.txt         Import document into the database
        b                                         Completely erase all data in embedding database.
        d                                         List topics in database.
        iTell Me about rubber ducks.              Call python script to gather documents with question, 
                                                  then forwards thos docs to chat_ollama to answer while 
                                                  preserving context.  Also, faster because model doesn'test
                                                  need to be loaded in python system.

      Provided that you have an enviornment properly set up and configured via VECTORDB_SYSTEM.PROPS, 
        results should be displayed.  My defaults are in "vectordb_python_api.h" in the 
        "VECTORDB_PYTHON_API_PROPERTIES" class.

0.015-241125
  - Rearranged some components.
  - Added a few of the scipts that I call to start things.
  - Added a few more python scipts.

0.014-241123
  - Changed fled_time to work with double instead of unsigned long.  Increases accuray.
  - The program time clock has been changed from system_clock to steady_clock.  Increases stability.

  - A few simple embedding tools were added, accessed by the first character of the input line:
      Example:
        m~/testdocs/rubberduckdetails.txt         Import document into the database
        eWrite a quick story about rubber ducks.  Request info about the documents in the database.

      Provided that you have an enviornment properly set up and configured via VECTORDB_SYSTEM.PROPS, 
        results should be displayed.  My defaults are in "vectordb_python_api.h" in the 
        "VECTORDB_PYTHON_API_PROPERTIES" class.

0.013-241122
  - A simple RAG call is wrapped in a thread.
  - Made a few changes to the CMakeList.txt file.
  
0.012-241121
  - Started wrapping embedding into a thread.

0.011-241115
  - Successful OllamaDB fetch made via Python scipts.
  - Clean up some tty_io routines.

0.010-241114
  - Slow progress. Embedding with RAG support still doesn't work.  I'm updating git 
      with the latest progress.

0.009-241105
  - Slow progress. Embedding with RAG support still doesn't work.  I'm updating git 
      with the latest progress.

0.008-241028
  - THIS BUILD DOES NOT WORK:
      On line 8 of ollama_api.h, if (#include "ollama.hpp") is not commented out, 
        line 54 of chromadb_api.cpp (chromadb::Client client("http", "localhost", "8000");)
        will throw the exceotion:
          Include this for: Fatal glibc error: pthread_mutex_lock.c:94 (___pthread_mutex_lock): assertion failed: mutex->__data.__owner == 0

0.007-241025
  - Restoration after system migration
  
0.006-241015
- Created a simple TTY_Interface. 
    Its not finished, and i didnt put any limit on the size of the text 
    box.  Works ok.  Probably spent more time on it than I should've.
- Changed other parts of the code.       

0.005_241014
  - Code is running better.
  - Context is working
  
0.004_241013
  - built ollama_api
  - built ollama_helper
  - built threading

0.003_241012
  - Async communication to Ollama is working but still needs 
      attention.
  - Corrected an errer if fled_time.

0.002_241011
  - Started building main structure.
  - Testing routines to see what works.

0.001_241010
  - First write, compile, and publish to github.